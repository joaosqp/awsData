3. SISTEMA DE ARMAZENAMENTOS DE DADOS
.Banco de dados relacionais são dados estruturados e com schema bem definido, que é criado antes do armazenamento dos dados. 
.Data Warehouse é criado com alguma tecnologia de banco relacional SGBD, Oracle, IBM, Microsoft SQL Server, PostgreeSQL, MySQL, entre outros, organizados em tabelas que se relacionam.
.Bancos não relacionais NoSQL, não precisa definir o schema antes do armazenamento ou pode ser definido no momento do armazenamento de dados.
.Data Wareahouse (DW) é um sistema de armazenamento que conecta e harmoniza grandes quantidades de dados com fontes diferentes, com o objetivo de alimentar a Business Intelligence, relatorios e análises e oferecer suporte aos requisitos de negócios, sendo armazenado em um onico lugar com dados antigos e atuais.
.Benefícios: Melhor análise de negócios, consultas mais rápidas, melhoria de qualidade dos dados, visão histórica.
.Data Lakes armazenas dados em forma bruta/formato original seja estruturado ou não, quando for analisar ele transforma o dado para análise. Tendo diferentes tipos de análises como SQL, análises de Big Data, analises em tempo real.
.DW e Data Lake utiliza os termos ETL(Extração, Transformação e Carga).
.Benefícios: Armazenamento em formato bruto, importação de qualquer quantidade de dados em tempo real, repositório central para todos os dados da empresa, sem necessidade de movimentação de dados.
.Data Store armazenamento não só de dados estruturados mas também como tipos variados como documentos, dados no formato chave valor, filas de mensagens entre outros.
.Benefícios: Armazenamento de variados tipos de dados, flexibilidade, suporta a dados semiestruturados, custo total menor.

4. ARMAZENAMENTO E PROCESSAMENTO PARALELO
.Cluster de computadores é um conjunto de servidores com o mesmo propósito, visando processar ou armazenar dados e possui escalabilidade horizontal, alem da escalabilidade vertical de cada máquina individual.
.Apache hadoop 
.Processamento paralelo o objetivo é dividir uma tarefa em varias sub-tarefas e executá-las em paralelo, Apache hadoop MapReduce é um framework com esse propósito.
.HDFS é um serviço rodando em todas as máquinas cluster, sendo um NameNode para gerenciar e os DataNodes que fazem o trabalho de armazenamento.
.MapReduce é um serviço que roda em todas as máquinas cluster, sendo o JobTracker para gerenciar os processamentos e os Task Tracker que fazem o trabalho, o JobTracker consulta o NameNode a fim de saber a localização dos blocos de dados.

5. CLOUD COMPUTING
.Principais provedoras AWS, AZURE, Google CLOUD

6. MLOPS E DATAOPS
.Machine Learning é uma sub-area da IA e da Ciência da computação que se concentra no uso de dados e algorítimos para imitar a forma de como os humanos aprendem, melhorando gradativamente sua precisão.
.PIPELINE de ML é o fluxo de trabalho / processo para que saia de uma ponta a outra em aprendizado de ML.
.MLOPS é um conjunto de praticas para colaboração e comunicação entre cientistas de dados e profissionais de operações, sendo normalmente Engenheiro de ML. A aplicação dessas praticas aumenta a qualidade, simplifica o processo de gerenciamento e automatiza a implantação de modelos de aprendizado de maquina em ambientes de produção em grande escala. é mais fácil alinhar os modelos as necessidades de negócios bem como aos requisitos regulamentares.
.MLOPS visa unificar o desenvolvimento de sistemas ML(DEV) e a implantação de sistemas de ML(OPS) para padronizar e agilizar a entrega continua de modelos de alto desempenho.
.DevOps é uma abordagem para desenvolvimento de software que acelera o ciclo de vida de construção usando automação. Ele se concentra na implantação contínua do software sem aproveitando recursos de TI, reduz o tempo de implantação, o tempo de lançamento no mercado e minimiza defeitos e o tempo para resolver problemas.
. MLOps - Operação de fluxo de trabalho em Machine Learning, AIOps - Operação do fluxo de trabalho em IA, DataOps - Conceito que abrange toda a operação de dados em uma empresa.
.DataOps(Operações de dados) é uma metodologia agil e orientada a processos para desenvolver e entregar analises, sendo capaz de habilitar soluções, desenvolver produtos de dados e ativar dados para valor comercial em todas as camadas de tecnologia, tendo como objetivo, agilizar o design, o desenvolvimento e a manutenção de aplicativos com base de dados e análise de dados.

7. DADOS COMO SERVIÇOS
.Data as a service(DaaS) é uma estrategia de dados de gerenciamento de dados que visa alavancar os dados como um ativo de negócios para maior agilidade no processo de análise, se tornou popupar nos anos 90 que começou com a introdução SaaS.
.DaaS forcene uma maneira de gerenciar as grandes quantidades de dados que as organizações geram todos os dias e essas informações valiosas são fornecidas em toda a empresa para a tomada de decisões baseada em dados.
.Arquitetura DaaS se concentra no provisionamento de dados de uma variedade de fontes sob demanda por meio de uso de APIs. Projetado para simplificar o acesso dos dados, o DaaS oferece conjuntos de daods ja tratados ou fluxos de dados para serem consumidos em uma variedade de formatos, geralmente unificados usando virtualização de dados (VIRTUAL DATA LAYER).
.DaaS pode incluir uma variedade de tecnologias de gerenciamento de dados, incluindo virtualização de dados, serviços de dados, análise de autoatendimento (Self-Service Analytics) e catalogo de dados.
.Beneficios: Monetização de dados, redução de custos, caminho mais rapido para inovação, agilidade no processo de decisão baseado em dados, menor risco no uso de dados, criação de uma cultura Data-Driven.

8. ETL - EXTRAÇÃO, TRANSFORMAÇÃO E CARGA DE DADOS
.CONCEITOS: 
ETL pode dar gargalos e perderem dados pois transforma o dado antes utilizado em DW, ELT ele transforma o dado depois de colocar em um data, utilizado em DL.

.9 COMO INICIAR UM PROJETO DE BIG DATA?
.Big Data Analytics são os valores obtidos por meio dos dados de big data, exemplos de empresas que utilizam o big data analytics, empresas financeiras, empresas de saude, site d namoro eHarmony utiliza  ambiente cloud em analises complexas criando resultados mais personalisados e aumentando a chance de sucesso nos relacionamentos. Sendo o Hadoop a principal fonte de armazenamento de BigData.
.Para inciar um projeto de Big Data: Definição do Business Case, Planejamento do projeto, Definição dos requisitos tecnicos, criação de um total 'business value assessment'.

